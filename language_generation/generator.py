import logging
import random
from simpletransformers.language_generation import LanguageGenerationModel


logging.basicConfig(level=logging.ERROR)
logging.getLogger("transformers").setLevel(logging.ERROR)


_MAX_LOADED_MODELS_ = 4
_MODELS_PATH_ = "trained_models"
_CATEGORY_MAPPING_ = {'Laptops': 'laptops',
                      'Cell Phones': 'cell_phones',
                      'Mens Running Shoes': 'mens_running_shoes',
                      'Vacuums': 'vacuums',
                      'Plush Figures': 'plush_figures'}


class Generator:

    def __init__(self, initial_category, initial_polarity):
        self.models = {}
        # load initial model
        if initial_category is not None and initial_polarity is not None:
            self.models[f"{initial_category}_{initial_polarity}"] = self.load_model(initial_category, initial_polarity)

    def load_model(self, category, polarity):
        """
        Loads the model to be used for Language Generation: Check if it is already loaded, if it is, return loaded
        model, otherwise load it from /trained_models. A maximum of _MAX_LOADED_MODELS_ can be loaded at the same time
        to avoid causing a crash due to lack of RAM. If this number is reached and a new model is loaded, remove the
        model which was loaded first before loading the new model.

        :param category: category of the model to be loaded
        :param polarity: sentiment class of the model to be loaded
        :return: LanguageGenerationModel object containing the model
        """
        if f"{category}_{polarity}" not in self.models:
            # print progress to console if model has to be loaded from file
            print(f"Loading model {category}, {polarity} --> ", end="")
            if len(self.models) >= _MAX_LOADED_MODELS_:
                del self.models[list(self.models.keys())[0]]
            model = LanguageGenerationModel("gpt2", f"{_MODELS_PATH_}/{category}_{polarity}")
            model.args.max_seq_length = 128
            model.args.max_length = 128
            self.models[f"{category}_{polarity}"] = model
            print("done")
        return self.models[f"{category}_{polarity}"]

    def generate(self, start, category, polarity, max_length=128):
        """
        Generate a text sequence using the requested model, limiting the generated texts length to max_length tokens.
        The start of the sequence is either manually set in parameter start or (if it is an empty string) a common
        sequence start is randomly selected.

        :param start: beginning of the sequence to generate (or empty string "" if none was defined)
        :param category: category of the requested model
        :param polarity: sentiment class of the requested model
        :param max_length: maximum number of tokens in the generated text
        :return: text sequence generated by the model
        """
        category = _CATEGORY_MAPPING_[category]
        model = self.load_model(category, polarity)
        start = self.adjust_start(start, polarity)
        if max_length != model.args.max_length:
            model.args.max_length = max_length
        return model.generate(start)[0]

    @staticmethod
    def adjust_start(start, polarity):
        """
        Helper method to select a random start for the sequence if none was defined. In this case it returns one of
        the very common starts in the training data, matching some strongly subjective common starts to the requested
        polarity.

        :param start: beginning of the sequence to generate (empty string "" if none was defined)
        :param polarity: sentiment class of the requested model
        :return: adjusted start of the sequence
        """
        if start.strip() == "":
            starts = ["I", "It", "The", "This", "Not"]
            starts += ["Excellent", "Great"] if polarity == "positive" else ["Poor", "Horrible"]
            start = random.choice(starts)
        return start
